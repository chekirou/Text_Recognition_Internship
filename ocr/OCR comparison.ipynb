{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class scrapper:\n",
    "    @staticmethod\n",
    "    def get_arks(year):\n",
    "        url_base = \"https://gallica.bnf.fr/ark:/12148/cb34363188x/date\"+str(year)+\"0101\"\n",
    "        req = requests.get(url_base, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        p = req.content\n",
    "        L = re.findall(r\"https://gallica.bnf.fr/ark:/(\\d*/(bpt\\w*))?\",str(p))\n",
    "        S = set()\n",
    "        for i in L:\n",
    "            if(i[1] != \"\"):\n",
    "                S.add(i[1])\n",
    "        return S\n",
    "    @staticmethod\n",
    "    def get_pagination(ark):\n",
    "        \"\"\"fonction qui renvoie le nombre de pages d'un documents\"\"\"\n",
    "        #print(cpt,\"--> https://gallica.bnf.fr/\"+i+\"/f7/highres\")\n",
    "        req = requests.get(\"https://gallica.bnf.fr/services/Pagination?ark=\" + ark)\n",
    "        p = req.content\n",
    "        pages = re.search(r\"<nbVueImages>(\\d*)</nbVueImages>\", str(p))\n",
    "        return pages.groups()[0]\n",
    "    @staticmethod\n",
    "    def get_page(ark, page, number = 1):\n",
    "        \n",
    "        req = requests.get(f\"https://gallica.bnf.fr/ark:/12148/{ark}/f{page}n{number}.texteBrut\")\n",
    "        return req.content\n",
    "    @staticmethod\n",
    "    def get_document(ark, mode = \"texteBrut\"):\n",
    "        req = requests.get(\"https://gallica.bnf.fr/ark:/12148/\"+ark+\".\"+ mode)\n",
    "        return req.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cleaner:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        pass\n",
    "    def extract(self, file):\n",
    "        soup = BeautifulSoup(file , \"html.parser\")\n",
    "        df = pd.DataFrame(columns=[\"page\", \"arrêt\", \"date\", \"juridiction\"])\n",
    "        Decision, notes, page, new_page = False, False, 0, True\n",
    "        for tag in soup.body : \n",
    "            if tag.name == \"hr\":\n",
    "                page += 1\n",
    "                notes = False\n",
    "                new_page  = True\n",
    "            if tag.name == \"p\" and tag.string is not None and not new_page:\n",
    "                m1 = re.match(r\".*?LA COUR(.+)\", tag.string)\n",
    "                m2 = re.match(r\"(.+?)Du(.+?\\d{3}.+?)(—|-)(.+?)(—|,).+\", tag.string ) \n",
    "                if not Decision and m1:\n",
    "                    Decision = True\n",
    "                    text = m1.groups()[0]\n",
    "                    First_page = page\n",
    "                elif Decision and m2 :\n",
    "                    Decision = False\n",
    "                    text += m2.groups()[0]\n",
    "                    date = m2.groups()[1]\n",
    "                    juridiction = m2.groups()[3]\n",
    "                    df = df.append({'page' : First_page, 'arrêt' : text , \"date\": date, \"juridiction\" : juridiction},ignore_index=True)\n",
    "                    text = ''\n",
    "                elif not notes and Decision:\n",
    "                    if not re.match(r\"^\\(\\d*\\).+$\", tag.string):\n",
    "                        text+= tag.string + \"\\n\"\n",
    "                    else:\n",
    "                        notes = True\n",
    "                else:\n",
    "                    pass\n",
    "            else :\n",
    "                new_page = False\n",
    "        return df\n",
    "    def save(self, df, ark):\n",
    "        df.to_csv(f\"{self.directory}/{ark}.csv\", encoding=\"utf-8\")\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bpt6k5745965s', 'bpt6k57460598'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = scrapper.get_arks(1830)\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = scrapper.get_page(\"bpt6k5745965s\", 179)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Cleaner(\"test\")\n",
    "file = scrapper.get_document(\"bpt6k5745965s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>arrêt</th>\n",
       "      <th>date</th>\n",
       "      <th>juridiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>; — Attendu , 1 °. que ces expressions de l'a...</td>\n",
       "      <td>12 mai 1830.</td>\n",
       "      <td>Ch. civ.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  page                                              arrêt           date  \\\n",
       "0    1   ; — Attendu , 1 °. que ces expressions de l'a...   12 mai 1830.   \n",
       "\n",
       "  juridiction  \n",
       "0   Ch. civ.   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Cleaner(\"test\")\n",
    "df = c.extract(file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "page                                                           1\n",
       "arrêt           ; — Attendu , 1 °. que ces expressions de l'a...\n",
       "date                                                12 mai 1830.\n",
       "juridiction                                            Ch. civ. \n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(file,ark, index_directories= \"test\"):\n",
    "    \"\"\"function to clean with a regex : a bit faster but with erros on the pages \"\"\"\n",
    "    soup = BeautifulSoup(file , \"html.parser\")\n",
    "    count = 1\n",
    "    df = pd.DataFrame(columns=[\"page\", \"arrêt\", \"date\", \"juridiction\"])\n",
    "    text = soup.text\n",
    "    complete = re.findall(r\"LA COUR(;|:).+?([A-Za-z].+?)\\. Du(.+?(\\d{3}|\\d{2}.\\d).+?)\\.?\\s?(—|-)(.+?)\\.?(—|,)\", text)\n",
    "    end = re.findall(r\"(.+)Du(.+?(\\d{3}|\\d{2}.\\d).+?)\\.?\\s?(—|-)(.+?)\\.?(—|,)\")\n",
    "    for _, arret, date, _,_,region,_ in m:\n",
    "        df = df.append({'page' : page, 'arrêt' : arret , \"date\": date, \"juridiction\" : region},ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(scrapper.get_page(\"bpt6k5745965s\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
