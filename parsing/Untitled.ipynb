{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"parsed/19110105.txt\", \"r\")\n",
    "text = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloads/19110101.pdf\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import BytesIO\n",
    "import argparse\n",
    "\n",
    "\n",
    "def SoupeURL(URL):\n",
    "    req = requests.get (URL , headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    p = req.content\n",
    "    B = BeautifulSoup (p , \"lxml\")\n",
    "    return B\n",
    "\n",
    "\n",
    "def Debaliser(string):\n",
    "    ch = str(string)\n",
    "    ch = ch.replace(\"<br/>\",\"\")\n",
    "    ch = re.sub (\"<.*?>\" ,\" \",str (ch))\n",
    "    ch = re.sub(\"^ *\",\"\",str(ch))\n",
    "    ch = re.sub(\"^\\s*\",\"\",str(ch))\n",
    "    ch = ch.rstrip()\n",
    "    return ch\n",
    "\n",
    "\"\"\"\n",
    "ça parcours entre les deux année avec comme limite un nombre de gazettes.\n",
    "ça retourne la liste des chemins ou y'a les pdf\n",
    "\"\"\"\n",
    "def parcourir_entre_deux(annee1,annee2, nb=200):\n",
    "    cpt = 0\n",
    "    cpt = cpt + 1\n",
    "    fichiers = []\n",
    "    for annee in range(annee1,annee2):\n",
    "        for mois in range(1,13):\n",
    "            for jour in range(1,32):\n",
    "                jour_f = str(jour)\n",
    "                if(len(jour_f) == 1):\n",
    "                    jour_f = \"0\"+jour_f\n",
    "                mois_f = str(mois)\n",
    "                if(len(mois_f) == 1):\n",
    "                    mois_f = \"0\" + mois_f\n",
    "                date = str(annee) + mois_f + jour_f\n",
    "                url = \"http://www.enap.justice.fr/ARCHIVE/\"+date+\".pdf\"\n",
    "                req = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                if(req.status_code == 200):\n",
    "                    f = open(\"downloads/\"+date+\".pdf\",\"wb\")\n",
    "                    fichiers.append(\"downloads/\"+date+\".pdf\")\n",
    "                    f.write(req.content)\n",
    "                if(len(fichiers) == nb):\n",
    "                    return fichiers\n",
    "\n",
    "def pdf2xt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = BytesIO()\n",
    "    device = TextConverter(rsrcmgr, retstr)\n",
    "    with open(path, \"rb\") as fp:  # open in 'rb' mode to read PDF bytes\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        for page in PDFPage.get_pages(fp, check_extractable=True):\n",
    "            interpreter.process_page(page)\n",
    "        device.close()\n",
    "        text = retstr.getvalue()\n",
    "        retstr.close()\n",
    "    return text\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    if not os.path.exists(\"parsed\"):\n",
    "        os.mkdir(\"parsed\")\n",
    "        print(\"Directory \", \"parsed\", \" Created \")\n",
    "\n",
    "\n",
    "    if not os.path.exists(\"downloads\"):\n",
    "        os.mkdir(\"downloads\")\n",
    "        print(\"Directory \", \"downloads\", \" Created \")\n",
    "\n",
    "    #Je teste sur un seul journal\n",
    "    pdf_path = parcourir_entre_deux(1911, 1920, 1)[0]\n",
    "    print(pdf_path)\n",
    "    content = (pdf2xt(pdf_path))\n",
    "    f = open(\"parsed/\"+pdf_path.split(\"/\")[-1].split(\".\")[0]+\".txt\",\"wb\")\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_arrets(file_path):\n",
    "    arrets = []\n",
    "    with open(file_path) as file:\n",
    "        content = file.read()\n",
    "        L = re.findall(\"« ((La Cour|Le Tribunal) ; (.*?))\\. » (.*?) —\", content)\n",
    "        for i in L:\n",
    "            arrets.append(i[0])\n",
    "    return arrets\n",
    "\n",
    "\n",
    "def extract_all(file_path):\n",
    "    with open(file_path) as file:\n",
    "        datas = []\n",
    "        content = file.read()\n",
    "        L = re.findall(\n",
    "            \"(((COUR|TRIBUNAL).*?) (Présidence de ((.*?).)) (Audience du ((\\d+) (\\w+) (\\d+\\.)))) (.*?) « ((La Cour|Le Tribunal) ; (.*?))\\. » (.*?) —\",\n",
    "            content)\n",
    "        for i in L:\n",
    "            print(\"====\")\n",
    "            juridiction = (i[1])\n",
    "            president = (i[5])\n",
    "            date = (i[6]).replace(\"Audience du \",\"\")\n",
    "            arret = (i[14])\n",
    "            datas.append((president,date,juridiction,arret))\n",
    "        return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def extract(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        datas = []\n",
    "        text = file.read()\n",
    "\n",
    "    df = pd.DataFrame(columns=[ \"arrêt\", \"date\", \"juridiction\"])\n",
    "    f = re.findall(r\"(?<!DU)(?<!«)((?: TRIBUNAL| COUR).+?) du ((?:\\S+ ){3})\", str(text))\n",
    "    s = re.split(r\"(?<!DU)(?<!«)(?:(?: TRIBUNAL| COUR).+?) du (?:(?:\\S+ ){3})\", str(text))\n",
    "    for (cour, date), string in zip(f, s[1:]):\n",
    "        m = re.findall(r\"((?:La Cour|Le Tribunal).+)\", string)\n",
    "        if len(m) > 0:\n",
    "            m2 = re.findall(r\"(.+)(?:»|OBS|■)\", m[-1])\n",
    "            if len(m2)> 0 :\n",
    "                df = df.append({ 'arrêt' : m2[0] , \"date\": date, \"juridiction\" : cour},ignore_index=True)\n",
    "            else:\n",
    "                df = df.append({ 'arrêt' : m[-1] , \"date\": date, \"juridiction\" : cour},ignore_index=True)\n",
    "    df[\"juridiction\"] = df[\"juridiction\"].apply(lambda x : re.split(r\"\\.|\\(\", x)[0] )\n",
    "    df[\"arrêt\"] = df[\"arrêt\"].apply(lambda x : re.split(r\"OBSERVATIONS\", x)[0] )\n",
    "    df[\"date\"] = df[\"date\"].apply(lambda x : re.split(r\"\\.\", x)[0] )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annee(annee):\n",
    "    annee = str(annee)\n",
    "    if not os.path.exists(\"cache/\"):\n",
    "        os.mkdir(\"cache/\")\n",
    "        print(\"Directory \", \"cache/\" , \" Created \")\n",
    "    if not os.path.exists(\"cache/\"+annee):\n",
    "        os.mkdir(\"cache/\"+annee)\n",
    "        print(\"Directory \", \"cache/\"+annee , \" Created \")\n",
    "    DF = pd.DataFrame(columns=[ \"arrêt\", \"date\", \"juridiction\", \"lien\", \"id\"])\n",
    "    for mois in range(1, 2):\n",
    "        for jour in range(2, 3):\n",
    "            jour_f = str(jour)\n",
    "            if (len(jour_f) == 1):\n",
    "                jour_f = \"0\" + jour_f\n",
    "            mois_f = str(mois)\n",
    "            if (len(mois_f) == 1):\n",
    "                mois_f = \"0\" + mois_f\n",
    "            date = str(annee) + mois_f + jour_f\n",
    "            url = \"http://www.enap.justice.fr/ARCHIVE/\" + date + \".pdf\"\n",
    "            print(annee, mois_f, jour_f)\n",
    "            req = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            if (req.status_code == 200):\n",
    "                print(mois,\"/\",jour)\n",
    "                f = open(\"tmp.bin\", \"wb\")\n",
    "                f.write(req.content)\n",
    "                f.close()\n",
    "                content = pdf2xt(\"tmp.bin\")\n",
    "                f = open(\"tmp.bin\", \"wb\")\n",
    "                f.write(content)\n",
    "                f.close()\n",
    "                df = extract(\"tmp.bin\")\n",
    "                df[\"lien\"] = url\n",
    "                df[\"id\"] = \"\" + annee +mois_f+jour_f + df.index.map(str)\n",
    "                DF = DF.append(df)\n",
    "            else:\n",
    "                url = \"http://data.decalog.net/enap1/liens/Gazette/ENAP_GAZETTE_TRIBUNAUX_\" + date + \".pdf\"\n",
    "                req = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                if (req.status_code == 200):\n",
    "                    print(mois,\"/\",jour)\n",
    "                    f = open(\"tmp.bin\", \"wb\")\n",
    "                    f.write(req.content)\n",
    "                    f.close()\n",
    "                    content = pdf2xt(\"tmp.bin\")\n",
    "                    f = open(\"tmp.bin\", \"wb\")\n",
    "                    f.write(content)\n",
    "                    f.close()\n",
    "                    df = extract(\"tmp.bin\")\n",
    "                    df[\"lien\"] = url\n",
    "                    df[\"id\"] = \"\" + annee +mois_f+jour_f + df.index.map(str)\n",
    "                    DF = DF.append(df)\n",
    "    DF.to_csv(f\"cache/{annee}/Gazette_des_tribunaux.csv\", encoding=\"utf-8\", sep = \";\")\n",
    "    return DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  cache/1864  Created \n",
      "1864 01 02\n",
      "1 / 2\n"
     ]
    }
   ],
   "source": [
    "df = get_annee(1864)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = open(\"tmp.bin\", \"r\" ,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(f\"cache/{1875}/Gazette_des_tribunaux.csv\", encoding=\"utf-8\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(columns=[ \"arrêt\", \"date\", \"juridiction\"])\n",
    "f = re.findall(r\"(?<!DU)(?<!«)((?: TRIBUNAL| COUR).+?) du ((?:\\S+ ){3})\", str(text))\n",
    "s = re.split(r\"(?<!DU)(?<!«)(?:(?: TRIBUNAL| COUR).+?) du (?:(?:\\S+ ){3})\", str(text))\n",
    "for (cour, date), string in zip(f, s[1:]):\n",
    "    m = re.findall(r\"(« (?:La (?:C|G)our|Le Tribunal).+?)(?:»|[A-Z]{3})\", string)\n",
    "    for message in m:\n",
    "        df = df.append({ 'arrêt' : message , \"date\": date, \"juridiction\" : cour},ignore_index=True)\n",
    "df[\"juridiction\"] = df[\"juridiction\"].apply(lambda x : re.split(r\"\\.|\\(\", x)[0] )\n",
    "df[\"arrêt\"] = df[\"arrêt\"].apply(lambda x : re.split(r\"OBSERVATIONS\", x)[0] )\n",
    "df[\"date\"] = df[\"date\"].apply(lambda x : re.split(r\"\\.\", x)[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"« La Cour ; « Considérant qu\\\\'au cours des années 1907\\\\' et 1908, Heurard de Fontgalland assurait d\\\\'abord contre l\\\\'incendie, puis contre le vol, un mobilier garnissant la villa Malgré tout, à Triel, louée par la demoiselle Lefèvre, sa maîtresse ; que, par des avenants succes-sifs,, il augmentait à diverses reprises le montant des capitaux assurés, de telle sorte que, s\\\\'il fallait en croire les déclarations conteaues dans ces actes, la valeur totale du mobilier aurait passé en dix-huit mois, de 20,000 à 35,000 francs ; que, dans cette somme, les tableaux et objets d\\\\'art portés, en 1907, pour 5,000 francs, figurent, en 1908, pour 12,000 francs-, et que les livres et documents précieux dont aucun n\\\\'est mentionné dans la police de 1907 comp-tent pour 5,000 francs dans l\\\\'avenant de 1908 ; que, dans le même laps de temps, l\\\\'argenterie passe de 500 à 2,000 francs, et les bijoux de 500 à 1,000 francs ; « Considérant qu\\\\'invité à s\\\\'expliquer sur les cau-ses d\\\\'un renchérissement aussi rapide et si notable, de Fontgalland n\\\\'a répondu que par des\""
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.arrêt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
